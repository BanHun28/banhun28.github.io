---
title: 무작정 따라하는 쿠버네티스 - 02
data: 2025-02-13 13:42:52 +0900
categories: [devops, containers]
tags: [kubernetes, k8s, devops, containers, orchestration, vm, vagrant, kubespray, tutorial, beginner, infrastructure]
image: assets/img/logos/kubernetes-logo.png
---



해당 문서는 쿠버네티스를 모르는 사람이 처음부터 끝까지 연습 할 수 있는 튜토리얼입니다.  

KubeSpray를 활용하여 클러스터를 구축합니다.  

## 2. k8s 구축하기 with [kubespray](https://kubespray.io/#/)
kubespray는 기본적으로 6개 이상의 노드일 때를 권장하지만,  
해당 실습은 노드 3개로 구성되어 있기 때문에  
모든 노드에 모든 역할을 부여합니다.  
### 1. [설치하기](https://kubernetes.io/ko/docs/setup/production-environment/tools/kubespray/#클러스터-생성하기)
생성이 완료되면 `kubespray-node`로 접속합니다
```sh
$ ssh vagrant@192.168.31.10 # password: vagrant
```
패키지를 업데이트하고 설치합니다.
```sh
$ sudo apt update
$ sudo apt install git python3 python3-pip -y
```
접속을 위해 키를 생성하고 배포합니다.  
`StrictHostKeyChecking` 옵션을 변경합니다.
```sh
$ ssh-keygen -t rsa -N '' -f ~/.ssh/id_rsa <<<y > /dev/null
$ ssh-copy-id 192.168.31.10
$ ssh-copy-id 192.168.31.20
$ ssh-copy-id 192.168.31.30
$ sudo sed -i '/StrictHostKeyChecking/c StrictHostKeyChecking no' /etc/ssh/ssh_config
# 접속확인
$ ssh -i ~/.ssh/id_rsa vagrant@192.168.31.10 'sudo hostname'
$ ssh -i ~/.ssh/id_rsa vagrant@192.168.31.20 'sudo hostname'
$ ssh -i ~/.ssh/id_rsa vagrant@192.168.31.30 'sudo hostname'
```
kubespray를 설치합니다.  
inventory_builder를 사용하는 버전으로 변경해야합니다.
```sh
git clone https://github.com/kubernetes-incubator/kubespray.git
cd kubespray/
pip install -r requirements.txt
# ansible path 등록
source ~/.profile
# 버전 변경 -> 2.26.0 버전 사용
git checkout f9ebd45
# sample 복제
cp -rfp inventory/sample/ inventory/mycluster/

pip3 install -r contrib/inventory_builder/requirements.txt
# k8s 타겟 노드들 선언
declare -a IPS=(192.168.31.10 192.168.31.20 192.168.31.30)
# 인벤토리 생성
CONFIG_FILE=inventory/mycluster/hosts.yml python3 contrib/inventory_builder/inventory.py ${IPS[@]}
```
생성된 파일을 변경합니다.
```yaml
# 변경 전
# inventory/mycluster/hosts.yml
all:
  hosts:
    node1:
      ansible_host: 192.168.31.10
      ip: 192.168.31.10
      access_ip: 192.168.31.10
    node2:
      ansible_host: 192.168.31.20
      ip: 192.168.31.20
      access_ip: 192.168.31.20
    node3:
      ansible_host: 192.168.31.30
      ip: 192.168.31.30
      access_ip: 192.168.31.30
  children:
    kube_control_plane:
      hosts:
        node1:
        node2:
    kube_node:
      hosts:
        node1:
        node2:
        node3:
    etcd:
      hosts:
        node1:
        node2:
        node3:
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
    calico_rr:
      hosts: {}
```
```yaml
# 변경 후.
# :se list 를 입력하여 tab 오류가 있는지 확인합니다.
# inventory/mycluster/hosts.yml
all:
  hosts:
    node1:
      ansible_host: 192.168.31.10
      ip: 192.168.31.10
      access_ip: 192.168.31.10
    node2:
      ansible_host: 192.168.31.20
      ip: 192.168.31.20
      access_ip: 192.168.31.20
    node3:
      ansible_host: 192.168.31.30
      ip: 192.168.31.30
      access_ip: 192.168.31.30
  children:
    kube_control_plane:
      hosts:
        node1:
        node2:
        node3: # 해당 위치에 노드 추가
    kube_node:
      hosts:
        node1:
        node2:
        node3:
    etcd:
      hosts:
        node1:
        node2:
        node3:
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
    calico_rr:
      hosts: {}
```
```sh
# 이 부분은 확인해봐야 합니다.
# $ sed -i 's/nf_conntrack_ipv4/nf_conntrack/' extra_playbooks/roles/kubernetes/node/tasks/main.yml
# $ sed -i 's/nf_conntrack_ipv4/nf_conntrack/' roles/kubernetes/node/tasks/main.yml
```
복제한 폴더에 들어가 원하는 옵션을 변경합니다.
```sh
# helm enable
$ sed -i 's/^helm_enabled: false$/helm_enabled: true/' inventory/mycluster/group_vars/k8s_cluster/addons.yml
# metric server enable
$ sed -i 's/^metrics_server_enabled: false$/metrics_server_enabled: true/' inventory/mycluster/group_vars/k8s_cluster/addons.yml
```
```yaml
# inventory/mycluster/group_vars/k8s_cluster/addons.yml
helm_enabled: true # false에서 변경
metrics_server_enabled: true # false에서 변경
```
```yaml
# inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml
# Choose network plugin (cilium, calico, kube-ovn, weave or flannel. Use cni for generic cni plugin)
# Can also be set to 'cloud', which lets the cloud provider setup appropriate routing
kube_network_plugin: calico # 원하는 플러그인으로 변경
```
kubespray를 실행합니다.
```sh
ansible-playbook -i inventory/mycluster/hosts.yml --become --become-user=root cluster.yml
```
정상적으로 설치되었다면 아래와 같은 문구가 마지막에 출력됩니다.  
모든 노드의 failed가 0이어야 합니다.
```
PLAY RECAP ******************************************************************************************************************************************
node1                      : ok=698  changed=151  unreachable=0    failed=0    skipped=1119 rescued=0    ignored=6
node2                      : ok=420  changed=86   unreachable=0    failed=0    skipped=645  rescued=0    ignored=1
node3                      : ok=420  changed=86   unreachable=0    failed=0    skipped=645  rescued=0    ignored=1
```
정상적으로 설치가 되었는지 확인
```sh
# ip 10, 20, 30 테스트해보면 됩니다.
$ ssh vagrant@192.168.31.10 "sudo kubectl get nodes"

NAME    STATUS   ROLES           AGE   VERSION
node1   Ready    control-plane   24m   v1.30.4
node2   Ready    control-plane   22m   v1.30.4
node3   Ready    control-plane   21m   v1.30.4

# 노드 메트릭 확인(metric-server가 정상적으로 설치되었다면.)
$ ssh vagrant@192.168.31.10 "sudo kubectl top nodes"

NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
node1   318m         17%    2683Mi          36%
node2   282m         15%    2035Mi          61%
node3   268m         14%    1959Mi          59%

$ ssh vagrant@192.168.31.10 "sudo kubectl get pods -n kube-system"

NAME                                      READY   STATUS    RESTARTS      AGE
calico-kube-controllers-b5f8f6849-6zq56   1/1     Running   0             22m
calico-node-9cn6w                         1/1     Running   0             23m
calico-node-jncdp                         1/1     Running   0             23m
calico-node-l8mfv                         1/1     Running   0             23m
coredns-776bb9db5d-5pfvp                  1/1     Running   0             21m
coredns-776bb9db5d-n64cd                  1/1     Running   0             21m
dns-autoscaler-6ffb84bd6-4rc66            1/1     Running   0             21m
kube-apiserver-node1                      1/1     Running   1             27m
kube-apiserver-node2                      1/1     Running   1             26m
kube-apiserver-node3                      1/1     Running   1             25m
kube-controller-manager-node1             1/1     Running   3             27m
kube-controller-manager-node2             1/1     Running   2             26m
kube-controller-manager-node3             1/1     Running   3             25m
kube-proxy-4fwb9                          1/1     Running   0             24m
kube-proxy-ss6pv                          1/1     Running   0             24m
kube-proxy-z92jj                          1/1     Running   0             24m
kube-scheduler-node1                      1/1     Running   1             27m
kube-scheduler-node2                      1/1     Running   1             26m
kube-scheduler-node3                      1/1     Running   2 (17m ago)   25m
metrics-server-8cfd759db-vwgg9            1/1     Running   0             19m
nodelocaldns-kdqm8                        1/1     Running   0             21m
nodelocaldns-sd77w                        1/1     Running   0             21m
nodelocaldns-snrdg                        1/1     Running   0             21m
```

### 2. 삭제하기
```sh
ansible-playbook -i inventory/mycluster/hosts.yml --become --become-user=root reset.yml
```
중간에 나오는 질문에 `yes` 입력.

### 3. [노드 관리](https://github.com/kubernetes-sigs/kubespray/blob/master/docs/operations/nodes.md)
#### worker node
##### 추가
##### 삭제
#### control node
##### 추가
##### 삭제


### 4. 트러블슈팅
#### ansible logging
자세한 로그 보기
```sh
$ ansible [COMMAND] -vvv 
```
#### 파이썬 패키지 오류
파이썬 패키지 확인하기
```sh
$ pip list
```
```sh
# 재설치
pip install -r requirements.txt
```

