---
title: Fundamentals of Machine Learning
date: 2025-08-13 12:29:40 +0900
categories: [machine learning, fundamentals]
tags: [machine learning, fundamentals, decision trees, linear regression, rule based learning, entropy, information gain, supervised learning, statistics, mathematics, algorithms]
math: true
---

머신러닝의 세계로 첫 발을 내딛는 개발자라면, 복잡한 딥러닝 모델보다는 기초적인 개념부터 차근차근 이해하는 것이 중요합니다. 오늘은 KAIST의 머신러닝 기초 강의를 바탕으로 가장 클래식한 머신러닝 접근법들과 그 수학적 원리를 쉽게 설명해보겠습니다.

## 머신러닝이란 무엇인가?

톰 미첼(Tom Mitchell)의 정의에 따르면:

> "컴퓨터 프로그램이 경험 E로부터 학습하여, 작업 T에 대한 성능 측정 P가 경험 E에 따라 향상된다면, 그 프로그램은 학습한다고 말할 수 있다."

즉, **더 많은 경험 → 더 나은 성능**이 머신러닝의 핵심입니다.

## 1. 규칙 기반 머신러닝 (Rule-Based Machine Learning)

### 완벽한 세상에서의 EnjoySport 문제

규칙 기반 학습을 이해하기 위해 "EnjoySport" 예제를 살펴보겠습니다. 사람들이 운동을 즐기는지 예측하는 문제입니다.

| Sky   | Temp | Humid  | Wind   | Water | Forecast | EnjoySport |
| ----- | ---- | ------ | ------ | ----- | -------- | ---------- |
| Sunny | Warm | Normal | Strong | Warm  | Same     | Yes        |
| Sunny | Warm | High   | Strong | Warm  | Same     | Yes        |
| Rainy | Cold | High   | Strong | Warm  | Change   | No         |
| Sunny | Warm | High   | Strong | Cool  | Change   | Yes        |

### Find-S 알고리즘

가장 특수한 가설부터 시작하여 점진적으로 일반화하는 방법:

1. 가장 특수한 가설 h로 초기화
2. 각 긍정적 사례에 대해:
   - 특징이 일치하면 그대로 유지
   - 일치하지 않으면 더 일반적으로 수정
3. 최종 가설 반환

### Version Space와 수학적 정의

**Version Space 공식:**

$$VS_{H,D} = \{h \in H | h \text{ is consistent with } D\}$$

**이 공식을 쉽게 설명하면:**

- $VS_{H,D}$: 우리가 찾고자 하는 "가능한 모든 좋은 규칙들의 집합"
- $H$: 생각할 수 있는 모든 규칙들
- $D$: 우리가 가진 데이터 (훈련 데이터)
- $S$: 가장 구체적인 규칙들 (Specific Boundary)
- $G$: 가장 일반적인 규칙들 (General Boundary)
- $g \geq h \geq s$: "일반적인 규칙 ≥ 우리 규칙 ≥ 구체적인 규칙" 순서

**비유로 이해하기:**
- S는 "매우 까다로운 기준" (예: 정확히 맑고, 따뜻하고, 습도 보통일 때만 운동)
- G는 "매우 관대한 기준" (예: 맑기만 하면 운동)
- 좋은 규칙은 이 둘 사이 어딘가에 있음

### 규칙 기반 학습의 한계

**완벽한 세상이라는 가정의 문제점:**
- 관측 오류 없음
- 비일관적 관측 없음
- 확률적 요소 없음

하지만 현실은 **노이즈와 불일치**로 가득하죠. 이로 인해 올바른 가설이 제거될 수 있습니다.

## 2. 의사결정 트리 (Decision Tree)

### 엔트로피 - 불확실성을 숫자로 표현하기

**엔트로피 공식:**

$$H(X) = -\sum_x P(X = x) \log_2 P(X = x)$$

**이 공식을 쉽게 설명하면:**

1. $P(X = x)$: 각 경우가 일어날 확률
   - 예: 동전 던지기에서 앞면이 나올 확률 = 0.5

2. $\log_2 P(X = x)$: 확률에 로그를 씌운 값 (항상 음수가 됨)
   - 확률이 낮을수록 더 큰 음수가 됨

3. $-$ 부호: 음수를 양수로 바꿔줌

4. $\sum$: 모든 경우를 더함

**직관적 이해:**
- 동전이 공평하면 (앞면 50%, 뒷면 50%) → 엔트로피 높음 (불확실성 높음)
- 동전이 조작되면 (앞면 90%, 뒷면 10%) → 엔트로피 낮음 (불확실성 낮음)

**실제 계산 예시:**
Credit Approval 데이터에서:
- 307개 승인, 383개 거부 (총 690개)

$$H(Y) = -\frac{307}{690}\log_2\frac{307}{690} - \frac{383}{690}\log_2\frac{383}{690}$$

단계별 계산:
1. $\frac{307}{690} = 0.445$ (승인 확률)
2. $\frac{383}{690} = 0.555$ (거부 확률)
3. $\log_2(0.445) = -1.167$
4. $\log_2(0.555) = -0.848$
5. $H(Y) = -(0.445 \times (-1.167) + 0.555 \times (-0.848)) = 0.990$

### 조건부 엔트로피 - "조건을 알면 얼마나 확실해질까?"

**조건부 엔트로피 공식:**

$$H(Y|X) = \sum_x P(X = x) H(Y|X = x)$$

**풀어서 설명하면:**

$$H(Y|X) = \sum_x P(X = x) \left\{-\sum_y P(Y = y|X = x) \log_2 P(Y = y|X = x)\right\}$$

**쉬운 이해:**
- "X를 알고 나서 Y가 얼마나 불확실한가?"
- 예: "A9(어떤 특성)를 알고 나서 승인/거부가 얼마나 불확실한가?"

**계산 과정:**
1. 각 X 값별로 Y의 엔트로피 계산
2. 각 엔트로피에 X가 그 값을 가질 확률을 곱함
3. 모든 경우를 더함

### 정보 이득 - "얼마나 도움이 되는가?"

**정보 이득 공식:**

$$IG(Y, A_i) = H(Y) - H(Y|A_i)$$

**쉬운 이해:**
- "특성 $A_i$를 사용하기 전 불확실성" - "사용한 후 불확실성"
- = "이 특성이 얼마나 도움이 되는가?"

**예시:**
- 원래 불확실성: 0.990
- A9를 안 후 불확실성: 0.565
- 정보 이득: 0.990 - 0.565 = 0.425

이는 "A9 특성을 사용하면 불확실성이 0.425만큼 줄어든다"는 뜻입니다.

### ID3 알고리즘

1. 초기 열린 노드 생성
2. 열린 노드가 없을 때까지 반복:
   - 분할할 열린 노드 선택
   - **정보 이득이 가장 큰** 변수 선택
   - 각 값에 대해 인스턴스 분류
   - 모든 인스턴스가 같은 클래스면 리프 노드로 종료

### 의사결정 트리의 문제점

**과적합(Overfitting)의 딜레마:**
- 훈련 데이터에서는 성능이 계속 향상
- 테스트 데이터에서는 성능이 하락

**언제 멈춰야 할까?**
- 가지치기(Pruning)
- 경로 길이 페널티
- 교차 검증

## 3. 선형 회귀 (Linear Regression)

### 기본 가설 - 선형 회귀가 예측하는 방법

**선형 회귀의 가설:**

$$h_\theta(x) = \theta_0 + \sum_{i=1}^n \theta_i x_i = \sum_{i=0}^n \theta_i x_i$$

이 무서워 보이는 공식을 차근차근 풀어보겠습니다.

#### 1단계: 기호들이 무엇을 의미하는지 알아보기

- **$h$**: 우리가 만든 예측 규칙 (hypothesis)
- **$h_\theta(x)$**: "주어진 정보 x로 결과를 예측하는 함수 (가설 함수)"
- **$x$**: 우리가 알고 있는 정보들 (예: 집의 방 개수, 평수, 위치 등)
- **$\theta$ (세타)**: 각 정보가 얼마나 중요한지를 나타내는 숫자들

#### 2단계: 각 부분을 하나씩 이해하기

**$\theta_0$ (세타 제로):**
- 이름: "기본값" 또는 "y절편"
- 의미: 모든 조건이 0일 때의 기본 값
- 예시: 방도 없고, 평수도 0인 땅의 기본 가격

**$\theta_i$ (세타 아이):**
- 이름: "각 특성의 중요도" 또는 "가중치"
- 의미: 각각의 정보가 결과에 얼마나 영향을 주는지
- 예시: 
  - $\theta_1 = 500$이면 "방 1개당 500만원"
  - $\theta_2 = 10$이면 "평수 1평당 10만원"

**$x_i$ (엑스 아이):**
- 이름: "각 특성의 값"
- 의미: 실제로 관측된 정보의 크기
- 예시:
  - $x_1 = 3$이면 "방이 3개"
  - $x_2 = 25$이면 "25평"

#### 3단계: 덧셈 기호 $\sum$ 이해하기

**$\sum_{i=1}^n \theta_i x_i$ 의 의미:**

- $\sum$ (시그마): "모두 더하기"라는 뜻
- $i=1$: 첫 번째 특성부터 시작
- $n$: 마지막 특성까지
- $\theta_i x_i$: 각 특성값 × 중요도

**풀어서 쓰면:**
$\sum_{i=1}^n \theta_i x_i = \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_3 + ... + \theta_n x_n$

#### 4단계: 전체 공식 이해하기

**$\theta_0 + \sum_{i=1}^n \theta_i x_i$ 는:**

기본값 + (특성1의 값 × 특성1의 중요도) + (특성2의 값 × 특성2의 중요도) + ...

#### 5단계: 실제 계산 예시

**집값 예측 상황:**
- 기본값: $\theta_0 = 1000$ (1000만원)
- 방 개수의 중요도: $\theta_1 = 500$ (방 1개당 500만원)
- 평수의 중요도: $\theta_2 = 10$ (1평당 10만원)
- 역세권 여부의 중요도: $\theta_3 = 300$ (역세권이면 300만원 추가)

**예측하고 싶은 집:**
- 방 개수: $x_1 = 3$
- 평수: $x_2 = 25$
- 역세권: $x_3 = 1$ (역세권이면 1, 아니면 0)

**계산 과정:**
$$h_\theta(x) = 1000 + (3 \times 500) + (25 \times 10) + (1 \times 300)$$
$$= 1000 + 1500 + 250 + 300 = 3050$$

**결과:** 이 집의 예상 가격은 **3,050만원**

#### 6단계: 왜 $\sum_{i=0}^n$ 으로도 쓸 수 있는가?

**트릭:** $x_0 = 1$로 정의하면

$$\theta_0 + \sum_{i=1}^n \theta_i x_i = \sum_{i=0}^n \theta_i x_i$$

왜냐하면:
- $\theta_0 x_0 = \theta_0 \times 1 = \theta_0$
- 따라서 $\theta_0$를 합계 안에 포함시킬 수 있음

**이렇게 하는 이유:** 수학적으로 더 깔끔하게 처리할 수 있어서

### 행렬 형태로 표현

$$\hat{y} = X\theta$$

**행렬 설명:**
- $X$: 모든 데이터를 표로 정리한 것 (각 행은 하나의 집, 각 열은 특성)
- $\theta$: 각 특성의 중요도를 세로로 나열한 것
- $\hat{y}$: 예측값들을 세로로 나열한 것

### 실제 세상은 노이즈가 있다

**노이즈를 고려한 모델:**

$$f(x; \theta) = \sum_{i=0}^n \theta_i x_i + e = y$$

또는 행렬로:

$$f = X\theta + e = Y$$

**설명:**
- $e$: 노이즈 (우리가 모르는 요소들)
- $Y$: 실제 관측된 값

### 최적의 θ 찾기

**목표:** 예측값과 실제값의 차이를 최소화

$$\hat{\theta} = \arg\min_\theta \|Y - X\theta\|^2 = \arg\min_\theta (Y - X\theta)^T(Y - X\theta)$$

**더 정확히는:**

$$\hat{\theta} = \arg\min_\theta (Y - X\theta)^T(Y - X\theta)$$

**이 공식을 풀어서 설명하면:**

1. $(Y - X\theta)$: 실제값 - 예측값 = 오차
2. $(Y - X\theta)^T(Y - X\theta)$: 오차들의 제곱을 모두 더한 것
3. $\arg\min_\theta$: 이 합을 가장 작게 만드는 $\theta$를 찾기

### 수학적 최적화 과정

**전개 과정:**

$$\arg\min_\theta (Y - X\theta)^T(Y - X\theta)$$

$$= \arg\min_\theta (\theta^T X^T X \theta - 2\theta^T X^T Y + Y^T Y)$$

**설명:**
- $Y^T Y$는 $\theta$와 무관하므로 최적화에서 제외
- 결국 $\theta^T X^T X \theta - 2\theta^T X^T Y$를 최소화

### 미분을 이용한 해답

**미분 = 0인 지점 찾기:**

$$\nabla_\theta (\theta^T X^T X \theta - 2\theta^T X^T Y) = 0$$

**미분 결과:**

$$2X^T X \theta - 2X^T Y = 0$$

**정리하면:**

$$X^T X \theta = X^T Y$$

**최종 해답:**

$$\theta = (X^T X)^{-1} X^T Y$$

**이 공식의 의미:**
- $(X^T X)^{-1} X^T$: 데이터의 특성을 고려한 "변환 행렬"
- $Y$: 실제 관측값
- 결과: 최적의 중요도들

### 특징 공학의 확장

**더 복잡한 관계 모델링:**

$$h_\theta(x) = \sum_{j=0}^m \theta_j \phi_j(x)$$

**설명:**
- $\phi_j(x_i)$: 특성을 변환하는 함수 (예: $x^2$, $\sqrt{x}$, $\sin(x)$ 등)
- 단순한 선형 관계가 아닌 곡선 관계도 모델링 가능

**주의사항:** 특징을 무작정 늘리면 과적합 위험이 증가합니다.

## 실무 관점에서의 교훈

### 1. 단순함의 힘

- **해석 가능성**: 의사결정 트리는 비전문가도 이해하기 쉬움
- **디버깅 용이성**: 규칙 기반 시스템은 문제 추적이 간단
- **빠른 프로토타이핑**: 간단한 모델로 빠른 검증 가능

### 2. 과적합 경계

```python
# 의사코드: 조기 종료 조건
def should_stop_training(validation_accuracy, patience=5):
    if len(validation_history) < patience:
        return False
    
    recent_accuracy = validation_history[-patience:]
    return not any(acc > max(validation_history[:-patience]) 
                  for acc in recent_accuracy)
```

### 3. 데이터 품질의 중요성

클래식한 방법들이 여전히 중요한 이유:
- **노이즈에 민감**: 데이터 품질 문제를 빨리 발견
- **기준선 제공**: 복잡한 모델의 성능 비교 기준
- **도메인 지식 활용**: 전문가의 규칙을 시스템에 반영

## 마무리: 고전이 주는 지혜

머신러닝의 발전사를 보면, 새로운 기법들이 기존 방법의 한계를 하나씩 해결해왔음을 알 수 있습니다:

1. **규칙 기반 → 의사결정 트리**: 노이즈 처리 개선
2. **의사결정 트리 → 선형 회귀**: 연속값 예측 지원
3. **선형 회귀 → 비선형 모델**: 복잡한 관계 모델링

하지만 여전히 이들 클래식 방법은:
- **빠른 프로토타이핑**
- **해석 가능한 모델링**
- **도메인 전문가와의 협업**

에서 핵심적인 역할을 합니다.

---

**참고문헌:**
- Bishop Chapter 14.4
- Mitchell Chapter 1,2,3
- KAIST 머신러닝 기초 강의 (Il-Chul Moon)

> 💡 **개발자 팁**: 새로운 머신러닝 프로젝트를 시작할 때는 항상 간단한 베이스라인 모델부터 구현해보세요. 의사결정 트리나 선형 회귀 같은 클래식한 방법들이 의외로 좋은 성능을 보여줄 때가 많습니다!

