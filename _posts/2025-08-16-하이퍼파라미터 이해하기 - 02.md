---
title: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì´í•´í•˜ê¸° - 02
date: 2025-08-16 10:57:56 +0900
categories: [artificial intelligence, machine learning]
tags: [machine learning, deep learning, hyperparameters, finetuning, llm, llamafactory, pytorch, optimization, training, scheduler, ai]     # TAG names should always be lowercase
---

# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì´í•´í•˜ê¸°.

## ğŸ“š ê°œë… ì´í•´

### í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ë€?

í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬(Learning Rate Scheduler)ëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ í•™ìŠµë¥ ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ê³ ì •ëœ í•™ìŠµë¥  ëŒ€ì‹ , í›ˆë ¨ ì§„í–‰ì— ë”°ë¼ í•™ìŠµë¥ ì„ ë³€ê²½í•˜ì—¬ ë” íš¨ê³¼ì ì¸ í•™ìŠµì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

```python
# ê¸°ë³¸ ê°œë…
ì´ˆê¸° í•™ìŠµë¥ : 5e-5
ìŠ¤ì¼€ì¤„ëŸ¬: cosine
ê²°ê³¼: 5e-5 â†’ ... â†’ ê±°ì˜ 0 (ì½”ì‚¬ì¸ ê³¡ì„ ì„ ë”°ë¼ ê°ì†Œ)
```

### ì™œ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ì´ í•„ìš”í•œê°€?

**1. ì´ˆê¸° ë‹¨ê³„**: í° í•™ìŠµë¥ ë¡œ ë¹ ë¥¸ ìˆ˜ë ´
**2. í›„ë°˜ ë‹¨ê³„**: ì‘ì€ í•™ìŠµë¥ ë¡œ ì •ë°€í•œ ìµœì í™”

```python
# ê³ ì • í•™ìŠµë¥ ì˜ ë¬¸ì œì 
learning_rate = 5e-4  # í•­ìƒ ë™ì¼

ë¬¸ì œ:
- ì´ˆê¸°: ëŠë¦° ìˆ˜ë ´
- í›„ë°˜: ìµœì ê°’ ì£¼ë³€ì—ì„œ ì§„ë™ (overshooting)

# ìŠ¤ì¼€ì¤„ë§ì˜ í•´ê²°ì±…
ì´ˆê¸°: í° í•™ìŠµë¥  â†’ ë¹ ë¥¸ ìˆ˜ë ´
í›„ë°˜: ì‘ì€ í•™ìŠµë¥  â†’ ì •ë°€í•œ ìµœì í™”
```

## ğŸ”„ LLaMA Factoryì—ì„œ ì§€ì›í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬

### 1. linear (ì„ í˜• ê°ì†Œ)

**ë™ì‘ ë°©ì‹**: í•™ìŠµë¥ ì´ ì„ í˜•ì ìœ¼ë¡œ ê°ì†Œí•©ë‹ˆë‹¤.

```python
# ìˆ˜í•™ì  ê³µì‹
lr(step) = max_lr * (1 - step / max_steps)

# ì‹¤ì œ ì˜ˆì‹œ (max_lr=5e-5, max_steps=1000)
Step 0:    lr = 5e-5  (100%)
Step 250:  lr = 3.75e-5 (75%)
Step 500:  lr = 2.5e-5  (50%)
Step 750:  lr = 1.25e-5 (25%)
Step 1000: lr = 0       (0%)
```

**ì„¤ì •**:
```yaml
lr_scheduler_type: linear
learning_rate: 5e-5
warmup_steps: 100  # warmup í›„ ì„ í˜• ê°ì†Œ ì‹œì‘
```

**ì¥ì **:
- ê°„ë‹¨í•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´
- ë¹ ë¥¸ ì´ˆê¸° í•™ìŠµê³¼ ì•ˆì •ì ì¸ ìˆ˜ë ´
- ë””ë²„ê¹…ì´ ì‰¬ì›€

**ë‹¨ì **:
- í›„ë°˜ë¶€ì— í•™ìŠµë¥ ì´ ë„ˆë¬´ ë¹¨ë¦¬ ê°ì†Œ
- ì§€ì—­ ìµœì ê°’ì— ë¹ ì§ˆ ìœ„í—˜

**ì í•©í•œ ìƒí™©**:
- ì§§ì€ í›ˆë ¨ (1-3 ì—í¬í¬)
- ì•ˆì •ì ì¸ ë°ì´í„°ì…‹
- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘

### 2. cosine (ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ë§)

**ë™ì‘ ë°©ì‹**: ì½”ì‚¬ì¸ í•¨ìˆ˜ë¥¼ ë”°ë¼ ë¶€ë“œëŸ½ê²Œ ê°ì†Œí•©ë‹ˆë‹¤.

```python
# ìˆ˜í•™ì  ê³µì‹  
lr(step) = min_lr + (max_lr - min_lr) * 0.5 * (1 + cos(Ï€ * step / max_steps))

# ì‹¤ì œ ì˜ˆì‹œ (max_lr=5e-5, min_lr=0, max_steps=1000)
Step 0:    lr = 5e-5     (100%)
Step 250:  lr = 3.54e-5  (â‰ˆ71%)  
Step 500:  lr = 2.5e-5   (50%)
Step 750:  lr = 1.46e-5  (â‰ˆ29%)
Step 1000: lr = 0        (0%)
```

**ì„¤ì •**:
```yaml
lr_scheduler_type: cosine
learning_rate: 5e-5
warmup_steps: 100
# cosine_restarts: false  # ê¸°ë³¸ê°’
```

**ì¥ì **:
- ë¶€ë“œëŸ¬ìš´ ê°ì†Œ ê³¡ì„ 
- í›„ë°˜ë¶€ê¹Œì§€ ì ì ˆí•œ í•™ìŠµë¥  ìœ ì§€
- ëŒ€ë¶€ë¶„ì˜ ìƒí™©ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥
- ì´ë¡ ì  ê·¼ê±°ê°€ íƒ„íƒ„í•¨

**ë‹¨ì **:
- ë³µì¡í•œ ìˆ˜í•™ì  ê³µì‹
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ ìƒëŒ€ì ìœ¼ë¡œ ì–´ë ¤ì›€

**ì í•©í•œ ìƒí™©**:
- ëŒ€ë¶€ë¶„ì˜ íŒŒì¸íŠœë‹ ì‘ì—… (ê¶Œì¥)
- ê¸´ í›ˆë ¨ ì‹œê°„
- ê³ í’ˆì§ˆ ê²°ê³¼ê°€ í•„ìš”í•œ ê²½ìš°

### 3. cosine_with_restarts (ì½”ì‚¬ì¸ ì¬ì‹œì‘)

**ë™ì‘ ë°©ì‹**: ì£¼ê¸°ì ìœ¼ë¡œ í•™ìŠµë¥ ì„ ì´ˆê¸°ê°’ìœ¼ë¡œ ë¦¬ì…‹í•˜ë©° ì½”ì‚¬ì¸ ê°ì†Œë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤.

```python
# ê°œë…
Period 1: 5e-5 â†’ 0 (1000 steps)
Restart:  ë‹¤ì‹œ 5e-5ë¶€í„° ì‹œì‘
Period 2: 5e-5 â†’ 0 (1000 steps)
...
```

**ì„¤ì •**:
```yaml
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
warmup_steps: 100
num_cycles: 3  # ì¬ì‹œì‘ íšŸìˆ˜
```

**ì¥ì **:
- ì§€ì—­ ìµœì ê°’ íƒˆì¶œ ê°€ëŠ¥
- ê¸´ í›ˆë ¨ì—ì„œ ì„±ëŠ¥ í–¥ìƒ
- ë‹¤ì–‘í•œ ìµœì ê°’ íƒìƒ‰

**ë‹¨ì **:
- ë³µì¡í•œ ì„¤ì •
- ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
- í›ˆë ¨ ì‹œê°„ ì¦ê°€

**ì í•©í•œ ìƒí™©**:
- ë§¤ìš° ê¸´ í›ˆë ¨ (10+ ì—í¬í¬)
- ë³µì¡í•œ ë°ì´í„°ì…‹
- ìµœê³  ì„±ëŠ¥ì´ í•„ìš”í•œ ì—°êµ¬

### 4. polynomial (ë‹¤í•­ì‹ ê°ì†Œ)

**ë™ì‘ ë°©ì‹**: ë‹¤í•­ì‹ í•¨ìˆ˜ë¥¼ ë”°ë¼ ê°ì†Œí•©ë‹ˆë‹¤.

```python
# ìˆ˜í•™ì  ê³µì‹ (power=1ì´ë©´ linearì™€ ë™ì¼)
lr(step) = max_lr * (1 - step / max_steps) ^ power

# power=2ì¸ ê²½ìš° (ì œê³± ê°ì†Œ)
Step 0:    lr = 5e-5    (100%)
Step 250:  lr = 2.81e-5 (â‰ˆ56%)
Step 500:  lr = 1.25e-5 (25%)
Step 750:  lr = 0.31e-5 (â‰ˆ6%)
Step 1000: lr = 0       (0%)
```

**ì„¤ì •**:
```yaml
lr_scheduler_type: polynomial
learning_rate: 5e-5
power: 2.0  # ê°ì†Œ ì •ë„ ì¡°ì ˆ
```

**ì¥ì **:
- ê°ì†Œ ê³¡ì„ ì„ ì„¸ë°€í•˜ê²Œ ì¡°ì ˆ ê°€ëŠ¥
- power ê°’ìœ¼ë¡œ ë‹¤ì–‘í•œ íŒ¨í„´ ìƒì„±

**ë‹¨ì **:
- ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„° (power) í•„ìš”
- ì¼ë°˜ì ìœ¼ë¡œ cosineë³´ë‹¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§

**ì í•©í•œ ìƒí™©**:
- íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°
- ì‹¤í—˜ì  ì—°êµ¬

### 5. constant (ìƒìˆ˜ ìœ ì§€)

**ë™ì‘ ë°©ì‹**: Warmup í›„ í•™ìŠµë¥ ì„ ì¼ì •í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.

```python
# íŒ¨í„´
Step 1-100:  0 â†’ 5e-5 (warmup)
Step 101+:   5e-5 (constant)
```

**ì„¤ì •**:
```yaml
lr_scheduler_type: constant
learning_rate: 5e-5
warmup_steps: 100
```

**ì¥ì **:
- ë§¤ìš° ê°„ë‹¨í•¨
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë™ì‘
- ì•ˆì •ì ì¸ í›ˆë ¨

**ë‹¨ì **:
- í›„ë°˜ë¶€ ìµœì í™” ë¶€ì¡±
- ì§€ì—­ ìµœì ê°’ì— ë¹ ì§ˆ ìœ„í—˜

**ì í•©í•œ ìƒí™©**:
- ë§¤ìš° ì§§ì€ í›ˆë ¨
- ì•ˆì •ì„±ì´ ìµœìš°ì„ ì¸ ê²½ìš°
- ë””ë²„ê¹… ëª©ì 

### 6. constant_with_warmup (ì›Œë°ì—… í›„ ìƒìˆ˜)

**ë™ì‘ ë°©ì‹**: `constant`ì™€ ë™ì¼í•˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ warmupì„ í‘œí˜„í•©ë‹ˆë‹¤.

```yaml
lr_scheduler_type: constant_with_warmup
learning_rate: 5e-5
warmup_steps: 100
```

### 7. inverse_sqrt (ì—­ì œê³±ê·¼ ê°ì†Œ)

**ë™ì‘ ë°©ì‹**: ì—­ì œê³±ê·¼ í•¨ìˆ˜ë¥¼ ë”°ë¼ ê°ì†Œí•©ë‹ˆë‹¤.

```python
# ìˆ˜í•™ì  ê³µì‹
lr(step) = max_lr / sqrt(max(step, warmup_steps))

# íŠ¹ì§•: ì´ˆê¸°ì—ëŠ” ë¹ ë¥´ê²Œ, í›„ë°˜ì—ëŠ” ì²œì²œíˆ ê°ì†Œ
```

**ì„¤ì •**:
```yaml
lr_scheduler_type: inverse_sqrt
learning_rate: 5e-5
warmup_steps: 100
```

**ì í•©í•œ ìƒí™©**:
- Transformer ëª¨ë¸ì˜ ì›ë˜ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©
- ì‚¬ì „ í›ˆë ¨ (pre-training)

## ğŸ“Š ì‹œê°ì  ë¹„êµ

### ê° ìŠ¤ì¼€ì¤„ëŸ¬ì˜ í•™ìŠµë¥  ë³€í™” íŒ¨í„´

```python
# 1000 steps, warmup 100 steps, initial_lr = 5e-5 ê¸°ì¤€

Linear:
  |\
  | \
  |  \
  |   \______
  0   100   1000

Cosine:
  |\
  | â•²
  |  â•²
  |   â•²___
  0   100   1000

Constant:
  |\
  | |â”€â”€â”€â”€â”€â”€â”€â”€
  |
  |
  0   100   1000

Polynomial (power=2):
  |\
  | â•²
  |  â•²â•²
  |    â•²â•²___
  0   100   1000
```

## ğŸ¯ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ

### ì‘ì—… ìœ í˜•ë³„ ê¶Œì¥ ìŠ¤ì¼€ì¤„ëŸ¬

#### 1. ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ ë¶„ë¥˜/ìƒì„±
```yaml
# ê°€ì¥ ì•ˆì „í•˜ê³  íš¨ê³¼ì ì¸ ì„ íƒ
lr_scheduler_type: cosine
learning_rate: 5e-5
warmup_steps: 100
num_train_epochs: 3
```

#### 2. ëŒ€í™”í˜• AI (ì±—ë´‡)
```yaml
# ì•ˆì •ì„±ê³¼ ì¼ê´€ì„± ì¤‘ì‹œ
lr_scheduler_type: cosine
learning_rate: 3e-5
warmup_steps: 200
num_train_epochs: 3
```

#### 3. ì½”ë“œ ìƒì„±
```yaml
# ì •í™•ì„± ì¤‘ì‹œ
lr_scheduler_type: linear
learning_rate: 1e-5
warmup_steps: 500
num_train_epochs: 5
```

#### 4. ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
```yaml
# ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ì„¤ì •
lr_scheduler_type: linear
learning_rate: 1e-4
warmup_steps: 50
num_train_epochs: 1
```

#### 5. ì—°êµ¬/ì‹¤í—˜ ëª©ì 
```yaml
# ìµœê³  ì„±ëŠ¥ ì¶”êµ¬
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
warmup_steps: 100
num_cycles: 2
num_train_epochs: 10
```

### ë°ì´í„°ì…‹ í¬ê¸°ë³„ ê¶Œì¥ì‚¬í•­

#### ì†Œê·œëª¨ ë°ì´í„°ì…‹ (< 1,000 ìƒ˜í”Œ)
```yaml
lr_scheduler_type: linear
learning_rate: 1e-4
warmup_steps: 20
num_train_epochs: 5

# ì´ìœ : ë¹ ë¥¸ ìˆ˜ë ´ì´ í•„ìš”, ê³¼ì í•© ìœ„í—˜
```

#### ì¤‘ê°„ ê·œëª¨ (1,000-10,000 ìƒ˜í”Œ)
```yaml
lr_scheduler_type: cosine
learning_rate: 5e-5
warmup_steps: 100
num_train_epochs: 3

# ì´ìœ : ê· í˜•ì¡íŒ ì ‘ê·¼
```

#### ëŒ€ê·œëª¨ (10,000+ ìƒ˜í”Œ)
```yaml
lr_scheduler_type: cosine
learning_rate: 3e-5
warmup_steps: 500
num_train_epochs: 2

# ì´ìœ : ì•ˆì •ì ì´ê³  ì •êµí•œ ìµœì í™”
```

### íŒŒì¸íŠœë‹ ë°©ë²•ë³„ ê¶Œì¥ì‚¬í•­

#### LoRA íŒŒì¸íŠœë‹
```yaml
# LoRAëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •ì 
lr_scheduler_type: cosine
learning_rate: 1e-4
warmup_steps: 100
```

#### QLoRA íŒŒì¸íŠœë‹
```yaml
# ì–‘ìí™”ë¡œ ì¸í•œ ë¶ˆì•ˆì •ì„± ê³ ë ¤
lr_scheduler_type: linear
learning_rate: 2e-4
warmup_steps: 200
```

#### Full Parameter íŒŒì¸íŠœë‹
```yaml
# ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”
lr_scheduler_type: cosine
learning_rate: 1e-5
warmup_steps: 1000
```

## ğŸ”¬ ê³ ê¸‰ ì„¤ì • ë° ì¡°í•©

### 1. ë‹¤ë‹¨ê³„ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§

ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í›ˆë ¨í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤:

```yaml
# Stage 1: ë¹ ë¥¸ ì ì‘
stage: sft
lr_scheduler_type: linear
learning_rate: 1e-4
warmup_steps: 100
num_train_epochs: 1
output_dir: saves/stage1

# Stage 2: ì •êµí•œ íŠœë‹ 
stage: sft
lr_scheduler_type: cosine
learning_rate: 3e-5
warmup_steps: 50
num_train_epochs: 2
model_name_or_path: saves/stage1  # Stage 1 ê²°ê³¼ ì‚¬ìš©
output_dir: saves/stage2
```

### 2. ë™ì  í•™ìŠµë¥  ì¡°ì •

ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ì—ì„œì˜ ì ì‘ì  ì ‘ê·¼:

```python
# ì˜ì‚¬ì½”ë“œ: ì„±ëŠ¥ì— ë”°ë¥¸ ë™ì  ì¡°ì •
if validation_lossê°€ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´:
    learning_rate *= 0.5
    lr_scheduler_type = "constant"  # ì•ˆì •í™”
else:
    lr_scheduler_type = "cosine"  # ê³„ì† ìµœì í™”
```

### 3. ì˜¨ë„ ìŠ¤ì¼€ì¤„ë§ê³¼ ê²°í•©

```yaml
# ê³ ê¸‰ ì„¤ì • ì˜ˆì‹œ
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
warmup_steps: 200
num_cycles: 3

# ì¶”ê°€ ìµœì í™” ê¸°ë²•ë“¤ê³¼ ê²°í•©
gradient_accumulation_steps: 8
gradient_checkpointing: true
fp16: true
```

## ğŸ“ˆ ì‹¤ì œ ì‚¬ë¡€ ë¶„ì„

### ì‚¬ë¡€ 1: ITEASY ê³ ê° ì§€ì› ì±—ë´‡

**ìš”êµ¬ì‚¬í•­**:
- 5,000ê°œ ê³ ê° ë¬¸ì˜ ë°ì´í„°
- 24/7 ì•ˆì •ì  ì„œë¹„ìŠ¤
- ì¼ê´€ëœ ì‘ë‹µ í’ˆì§ˆ

**1ì°¨ ì‹œë„ (ì‹¤íŒ¨)**:
```yaml
lr_scheduler_type: linear
learning_rate: 1e-3  # ë„ˆë¬´ í° í•™ìŠµë¥ 
warmup_steps: 10     # ë„ˆë¬´ ì§§ì€ warmup
num_train_epochs: 1

ê²°ê³¼: ë¶ˆì•ˆì •í•œ í•™ìŠµ, ì¼ê´€ì„± ì—†ëŠ” ì‘ë‹µ
```

**ìµœì¢… ì„±ê³µ ì„¤ì •**:
```yaml
lr_scheduler_type: cosine
learning_rate: 3e-5  # ì•ˆì •ì ì¸ í•™ìŠµë¥ 
warmup_steps: 300    # ì¶©ë¶„í•œ warmup
num_train_epochs: 3
per_device_train_batch_size: 4
gradient_accumulation_steps: 8

ê²°ê³¼: 
- ì•ˆì •ì ì¸ loss ê°ì†Œ
- ì¼ê´€ëœ ì‘ë‹µ í’ˆì§ˆ
- ê³ ê° ë§Œì¡±ë„ 95% ë‹¬ì„±
```

### ì‚¬ë¡€ 2: ê¸°ìˆ  ë¬¸ì„œ ìë™ ìš”ì•½

**ìš”êµ¬ì‚¬í•­**:
- 50,000ê°œ ê¸°ìˆ  ë¬¸ì„œ
- ì •í™•í•œ ìš”ì•½ ìƒì„±
- ê¸´ ë¬¸ì„œ ì²˜ë¦¬ (2048 í† í°)

**ì‹¤í—˜ ê²°ê³¼**:

```yaml
# ì‹¤í—˜ A: Linear scheduler
lr_scheduler_type: linear
learning_rate: 5e-5
ROUGE-L: 0.42

# ì‹¤í—˜ B: Cosine scheduler  
lr_scheduler_type: cosine
learning_rate: 5e-5
ROUGE-L: 0.47  # 5% ê°œì„ 

# ì‹¤í—˜ C: Cosine with restarts
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
num_cycles: 2
ROUGE-L: 0.49  # ìµœê³  ì„±ëŠ¥
```

**ì„ íƒëœ ìµœì¢… ì„¤ì •**:
```yaml
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
warmup_steps: 500
num_cycles: 2
num_train_epochs: 4
```

### ì‚¬ë¡€ 3: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ (ì—°êµ¬ìš©)

**ìš”êµ¬ì‚¬í•­**:
- ë¹ ë¥¸ ê²°ê³¼ í™•ì¸
- ë‹¤ì–‘í•œ ì•„ì´ë””ì–´ í…ŒìŠ¤íŠ¸
- ì œí•œëœ GPU ì‹œê°„

**ìµœì í™”ëœ ì„¤ì •**:
```yaml
lr_scheduler_type: linear
learning_rate: 2e-4  # í° í•™ìŠµë¥ ë¡œ ë¹ ë¥¸ ìˆ˜ë ´
warmup_steps: 20     # ìµœì†Œí•œì˜ warmup
num_train_epochs: 1
max_samples: 1000    # ì‘ì€ ë°ì´í„°ì…‹

ê²°ê³¼: 30ë¶„ ë§Œì— ê¸°ë³¸ ì„±ëŠ¥ í™•ì¸ ê°€ëŠ¥
```

## ğŸš¨ í”í•œ ì‹¤ìˆ˜ì™€ í•´ê²°ë°©ë²•

### ì‹¤ìˆ˜ 1: ìŠ¤ì¼€ì¤„ëŸ¬ì™€ í•™ìŠµë¥  ë¶ˆì¼ì¹˜

**ë¬¸ì œ**:
```yaml
lr_scheduler_type: cosine
learning_rate: 1e-3  # ìŠ¤ì¼€ì¤„ëŸ¬ì— ë¹„í•´ ë„ˆë¬´ í° í•™ìŠµë¥ 
```

**ì¦ìƒ**: ì´ˆê¸° ë¶ˆì•ˆì •, NaN ë°œìƒ

**í•´ê²°**:
```yaml
lr_scheduler_type: cosine
learning_rate: 5e-5  # ìŠ¤ì¼€ì¤„ëŸ¬ì— ì í•©í•œ í•™ìŠµë¥ 
warmup_steps: 200    # ì¶©ë¶„í•œ warmup
```

### ì‹¤ìˆ˜ 2: ì§§ì€ í›ˆë ¨ì— ë³µì¡í•œ ìŠ¤ì¼€ì¤„ëŸ¬

**ë¬¸ì œ**:
```yaml
num_train_epochs: 1
max_steps: 100
lr_scheduler_type: cosine_with_restarts  # ë³µì¡í•œ ìŠ¤ì¼€ì¤„ëŸ¬
```

**í•´ê²°**:
```yaml
num_train_epochs: 1
max_steps: 100
lr_scheduler_type: linear  # ê°„ë‹¨í•œ ìŠ¤ì¼€ì¤„ëŸ¬
```

### ì‹¤ìˆ˜ 3: Warmupê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ ì¶©ëŒ

**ë¬¸ì œ**:
```yaml
warmup_steps: 500
max_steps: 600       # warmupì´ ì „ì²´ í›ˆë ¨ì˜ 83%
lr_scheduler_type: cosine
```

**í•´ê²°**:
```yaml
warmup_steps: 60     # ì „ì²´ì˜ 10%
max_steps: 600
lr_scheduler_type: cosine
```

## ğŸ”§ ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§

### í•™ìŠµë¥  ë³€í™” ëª¨ë‹ˆí„°ë§

```yaml
# ìƒì„¸ ë¡œê¹… ì„¤ì •
logging_steps: 10
report_to: tensorboard
use_swanlab: true

# ê´€ì°°í•  ì§€í‘œë“¤:
# - learning_rate: í˜„ì¬ í•™ìŠµë¥ 
# - train_loss: ì†ì‹¤ í•¨ìˆ˜ ê°’
# - eval_loss: ê²€ì¦ ì†ì‹¤
```

### TensorBoardì—ì„œ í™•ì¸í•  íŒ¨í„´

#### ì •ìƒì ì¸ íŒ¨í„´
```python
# í•™ìŠµë¥  ê·¸ë˜í”„
- Warmup êµ¬ê°„: 0ì—ì„œ ëª©í‘œê°’ê¹Œì§€ ì„ í˜• ì¦ê°€
- Main êµ¬ê°„: ìŠ¤ì¼€ì¤„ëŸ¬ì— ë”°ë¥¸ ë¶€ë“œëŸ¬ìš´ ê°ì†Œ

# Loss ê·¸ë˜í”„  
- ì´ˆê¸°: ë¹ ë¥¸ ê°ì†Œ
- ì¤‘ê°„: ì•ˆì •ì  ê°ì†Œ
- í›„ë°˜: ëŠë¦° ê°ì†Œ ë˜ëŠ” ìˆ˜ë ´
```

#### ë¬¸ì œê°€ ìˆëŠ” íŒ¨í„´
```python
# í•™ìŠµë¥ ì´ ë„ˆë¬´ í´ ë•Œ
- Lossê°€ ì§„ë™í•˜ê±°ë‚˜ ë°œì‚°
- NaN ê°’ ë°œìƒ

# í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ì„ ë•Œ  
- Loss ê°ì†Œê°€ ë§¤ìš° ëŠë¦¼
- ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ

# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì˜¤ë¥˜
- í•™ìŠµë¥ ì´ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ë³€í™”
- ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”
```

### ì‹¤ì‹œê°„ ì¡°ì • ê¸°ë²•

```python
# Early stoppingê³¼ ê²°í•©
early_stopping_patience: 3
early_stopping_threshold: 0.01

# ìë™ í•™ìŠµë¥  ê°ì†Œ
reduce_lr_on_plateau: true
reduce_lr_factor: 0.5
reduce_lr_patience: 2
```

## ğŸ’¡ ê³ ê¸‰ ìµœì í™” íŒ

### 1. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•

```yaml
# Phase 1: ë¹ ë¥¸ ì ì‘ (Linear)
lr_scheduler_type: linear
learning_rate: 1e-4
num_train_epochs: 1

# Phase 2: ì •êµí•œ ìµœì í™” (Cosine)  
lr_scheduler_type: cosine
learning_rate: 3e-5
num_train_epochs: 2
```

### 2. ë„ë©”ì¸ë³„ ìµœì í™”

```yaml
# ì°½ì‘/ëŒ€í™” (ì°½ì˜ì„± ì¤‘ì‹œ)
lr_scheduler_type: constant_with_warmup
learning_rate: 5e-5

# ì½”ë“œ/ë¶„ì„ (ì •í™•ì„± ì¤‘ì‹œ)
lr_scheduler_type: cosine
learning_rate: 1e-5

# ë¶„ë¥˜/ì¶”ì¶œ (íš¨ìœ¨ì„± ì¤‘ì‹œ)
lr_scheduler_type: linear  
learning_rate: 1e-4
```

### 3. ë¦¬ì†ŒìŠ¤ë³„ ìµœì í™”

```yaml
# ê³ ì„±ëŠ¥ GPU (A100, H100)
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
per_device_train_batch_size: 16

# ì¤‘ê°„ GPU (RTX 4090, V100)
lr_scheduler_type: cosine
learning_rate: 5e-5  
per_device_train_batch_size: 8

# ì €ì‚¬ì–‘ GPU (RTX 3080, 4060)
lr_scheduler_type: linear
learning_rate: 1e-4
per_device_train_batch_size: 2
```

## ğŸ“‹ ìµœì¢… ê¶Œì¥ì‚¬í•­

### ìƒí™©ë³„ ë¹ ë¥¸ ì„ íƒ ê°€ì´ë“œ

#### ğŸš€ ì²˜ìŒ ì‚¬ìš©ì
```yaml
lr_scheduler_type: cosine
learning_rate: 5e-5
warmup_steps: 100
```

#### âš¡ ë¹ ë¥¸ ì‹¤í—˜
```yaml
lr_scheduler_type: linear  
learning_rate: 1e-4
warmup_steps: 50
```

#### ğŸ¯ í”„ë¡œë•ì…˜
```yaml
lr_scheduler_type: cosine
learning_rate: 3e-5
warmup_steps: 300
```

#### ğŸ”¬ ì—°êµ¬ ëª©ì 
```yaml
lr_scheduler_type: cosine_with_restarts
learning_rate: 5e-5
warmup_steps: 200
num_cycles: 2
```

### ì„±ëŠ¥ ìˆœìœ„ (ì¼ë°˜ì ì¸ ê²½ìš°)

1. **cosine** - ê°€ì¥ ë²”ìš©ì ì´ê³  ì•ˆì •ì 
2. **linear** - ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ìˆ˜ë ´
3. **cosine_with_restarts** - ìµœê³  ì„±ëŠ¥ (ë³µì¡í•¨)
4. **constant** - ì•ˆì •ì„± ìµœìš°ì„ 
5. **polynomial** - íŠ¹ìˆ˜ ëª©ì 

í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ëª¨ë¸ ì„±ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ì ì ˆí•œ ì„ íƒê³¼ ì„¤ì •ì„ í†µí•´ í›¨ì”¬ ë” íš¨ê³¼ì ì¸ íŒŒì¸íŠœë‹ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
