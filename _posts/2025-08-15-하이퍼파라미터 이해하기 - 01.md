---
title: 하이퍼파라미터 이해하기 - 01
date: 2025-08-15 10:57:50 +0900
categories: [artificial intelligence, machine learning]
tags: [machine learning, deep learning, hyperparameters, finetuning, llm, llamafactory, pytorch, optimization, training, warmup, ai]     # TAG names should always be lowercase
---

# Warmup 이해하기. 

## 📚 개념 이해

### Warmup?

**Warmup**은 훈련 초기에 학습률을 점진적으로 증가시키는 기법입니다. 처음에는 매우 작은 학습률로 시작해서 지정된 스텝 수에 걸쳐 목표 학습률까지 서서히 올려갑니다.

```python
# Warmup 과정 예시
초기 학습률: 0 (또는 매우 작은 값)
목표 학습률: 5e-5
warmup_steps: 100

Step 1:   학습률 = 5e-7  (목표의 1%)
Step 50:  학습률 = 2.5e-5 (목표의 50%)  
Step 100: 학습률 = 5e-5   (목표의 100%)
Step 101+: 스케줄러에 따라 감소/유지
```

## 🎯 Warmup이 필요한 이유

### 1. 그래디언트 폭발 방지

**문제상황**:
```python
# 훈련 시작 시 큰 학습률로 인한 문제
초기 가중치: 무작위 초기화 상태
큰 학습률: 5e-4
결과: 그래디언트가 폭발하여 loss가 발산
```

**Warmup 해결책**:
```python
# 점진적 학습률 증가로 안정화
Step 1-100: 작은 학습률로 안정적 초기 학습
Step 101+: 본격적인 학습률로 효율적 학습
```

### 2. Adam 옵티마이저의 편향 문제

Adam 옵티마이저는 초기에 모멘텀 추정치가 0에 편향되어 있습니다:

```python
# Adam의 내부 상태
m_t = 0  # 1차 모멘텀 (초기값)
v_t = 0  # 2차 모멘텀 (초기값)

# 편향 보정이 필요한 초기 단계
m_hat = m_t / (1 - beta1^t)  # 편향 보정
v_hat = v_t / (1 - beta2^t)  # 편향 보정
```

Warmup은 이 편향이 자연스럽게 해결될 시간을 제공합니다.

### 3. 사전훈련된 모델의 안정성

파인튜닝 시 사전훈련된 가중치를 급격히 변화시키지 않도록 합니다:

```python
# 사전훈련된 모델의 특성
- 이미 좋은 표현을 학습한 상태
- 급격한 변화는 기존 지식을 파괴할 수 있음
- 점진적 적응이 필요
```

## ⚙️ LLaMA Factory에서의 warmup_steps 설정

### 기본 설정
```yaml
warmup_steps: 100  # 기본값: 0 (warmup 없음)
```

### 다양한 설정 방법

#### 1. 절대값으로 설정
```yaml
warmup_steps: 500  # 정확히 500 스텝 동안 warmup
```

#### 2. 비율로 설정 (일부 프레임워크)
```yaml
warmup_ratio: 0.1  # 전체 훈련 스텝의 10%
```

### 실제 계산 예시

```python
# 설정 예시
total_samples = 10000
per_device_batch_size = 8
gradient_accumulation_steps = 4
num_epochs = 3
num_gpus = 2

# 계산
effective_batch_size = per_device_batch_size * gradient_accumulation_steps * num_gpus
# = 8 * 4 * 2 = 64

steps_per_epoch = total_samples / effective_batch_size
# = 10000 / 64 = 156.25 ≈ 156

total_steps = steps_per_epoch * num_epochs
# = 156 * 3 = 468

# Warmup 설정 권장사항
warmup_steps = total_steps * 0.1  # 전체의 10%
# = 468 * 0.1 = 46.8 ≈ 47
```

## 📊 적절한 warmup_steps 값 선택

### 데이터셋 크기별 권장값

#### 소규모 데이터셋 (< 1,000 샘플)
```yaml
warmup_steps: 10-50
# 이유: 전체 훈련이 짧아서 긴 warmup은 비효율적
```

#### 중간 규모 데이터셋 (1,000-10,000 샘플)
```yaml
warmup_steps: 50-200
# 이유: 적당한 안정화 기간 필요
```

#### 대규모 데이터셋 (> 10,000 샘플)
```yaml
warmup_steps: 200-1000
# 이유: 충분한 안정화로 전체 성능 향상
```

### 모델 크기별 권장값

#### 작은 모델 (< 1B 파라미터)
```yaml
warmup_steps: 50-100
learning_rate: 1e-4
# 작은 모델은 상대적으로 안정적
```

#### 중간 모델 (1B-10B 파라미터)  
```yaml
warmup_steps: 100-500
learning_rate: 5e-5
# 균형잡힌 접근
```

#### 큰 모델 (> 10B 파라미터)
```yaml
warmup_steps: 500-1000
learning_rate: 1e-5
# 큰 모델일수록 신중한 warmup 필요
```

### 파인튜닝 방법별 권장값

#### LoRA 파인튜닝
```yaml
warmup_steps: 50-200
learning_rate: 1e-4
# LoRA는 상대적으로 안정적이라 짧은 warmup
```

#### Full Parameter 파인튜닝
```yaml
warmup_steps: 200-1000
learning_rate: 5e-6
# 전체 가중치 변경으로 긴 warmup 필요
```

#### QLoRA 파인튜닝
```yaml
warmup_steps: 100-300
learning_rate: 2e-4
# 양자화로 인한 불안정성 고려
```

## 🔬 학습률 스케줄러와의 상호작용

### Linear Scheduler + Warmup
```python
# 스케줄 예시 (1000 total steps, 100 warmup steps)
Step 1-100:   0 → target_lr (linear increase)
Step 101-1000: target_lr → 0 (linear decrease)
```

```yaml
warmup_steps: 100
lr_scheduler_type: linear
learning_rate: 5e-5
num_train_epochs: 3
```

### Cosine Scheduler + Warmup
```python
# 스케줄 예시
Step 1-100:   0 → target_lr (linear warmup)
Step 101-1000: target_lr → min_lr (cosine decay)
```

```yaml
warmup_steps: 100
lr_scheduler_type: cosine
learning_rate: 5e-5
num_train_epochs: 3
```

### Constant Scheduler + Warmup
```python
# 스케줄 예시
Step 1-100:   0 → target_lr (linear warmup)
Step 101-1000: target_lr (constant)
```

```yaml
warmup_steps: 100
lr_scheduler_type: constant
learning_rate: 5e-5
```

## 📈 실무 적용 사례

### 사례 1: 고객 지원 챗봇 개발

```yaml
# 환경: 호스팅 업계 고객 문의 데이터
# 데이터: 5,000개 고객 문의-응답 쌍
# 목표: 안정적이고 일관된 응답 생성

model_name_or_path: Qwen/Qwen2.5-7B-Instruct
template: qwen
stage: sft
finetuning_type: lora

# 데이터셋
dataset: customer_support_ko
cutoff_len: 1024
max_samples: 5000

# 학습 설정
learning_rate: 5e-5
num_train_epochs: 3
per_device_train_batch_size: 4
gradient_accumulation_steps: 8

# Warmup 설정 (신중한 접근)
warmup_steps: 200
lr_scheduler_type: cosine

# 계산:
# total_steps ≈ 5000/(4*8) * 3 = 468 steps
# warmup_steps = 200 (전체의 ~43%)
# 이유: 고객 응답의 일관성이 중요하므로 충분한 warmup
```

### 사례 2: 기술 문서 요약 모델

```yaml
# 환경: 서버 관리 문서 요약
# 데이터: 50,000개 기술 문서
# 목표: 정확하고 간결한 요약

model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct
template: llama3
stage: sft
finetuning_type: lora

# 데이터셋  
dataset: tech_docs_summary
cutoff_len: 2048
max_samples: 50000

# 학습 설정
learning_rate: 3e-5
num_train_epochs: 2
per_device_train_batch_size: 8
gradient_accumulation_steps: 4

# Warmup 설정 (표준 접근)
warmup_steps: 300
lr_scheduler_type: cosine

# 계산:
# total_steps ≈ 50000/(8*4) * 2 = 3125 steps  
# warmup_steps = 300 (전체의 ~10%)
# 이유: 대규모 데이터셋으로 표준적인 warmup 비율
```

### 사례 3: 빠른 프로토타이핑

```yaml
# 환경: 빠른 개념 검증
# 데이터: 1,000개 샘플
# 목표: 최대한 빠른 결과 확인

model_name_or_path: microsoft/Phi-3-mini-4k-instruct
template: phi
stage: sft
finetuning_type: qlora
quantization_bit: 4

# 데이터셋
dataset: alpaca_en_demo
cutoff_len: 512
max_samples: 1000

# 학습 설정
learning_rate: 1e-4
num_train_epochs: 1
per_device_train_batch_size: 2
gradient_accumulation_steps: 8

# Warmup 설정 (최소한)
warmup_steps: 20
lr_scheduler_type: linear

# 계산:
# total_steps ≈ 1000/(2*8) * 1 = 62.5 steps
# warmup_steps = 20 (전체의 ~32%)
# 이유: 짧은 훈련이지만 최소한의 안정성 확보
```

## 🚨 일반적인 실수와 해결방법

### 실수 1: Warmup이 너무 길 때

**문제**:
```yaml
total_steps: 100
warmup_steps: 80  # 전체의 80%!
```

**증상**:
- 실제 학습 시간이 너무 짧음
- 목표 학습률에 도달하자마자 훈련 종료
- 성능 향상이 미미함

**해결**:
```yaml
total_steps: 100
warmup_steps: 10  # 전체의 10%
```

### 실수 2: Warmup이 너무 짧을 때

**문제**:
```yaml
learning_rate: 1e-3  # 매우 큰 학습률
warmup_steps: 5      # 매우 짧은 warmup
```

**증상**:
- 초기 loss가 발산하거나 불안정
- NaN 값 발생
- 훈련이 실패

**해결**:
```yaml
learning_rate: 1e-4  # 학습률 감소
warmup_steps: 50     # warmup 증가
```

### 실수 3: 큰 모델에 부적절한 설정

**문제**:
```yaml
model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
finetuning_type: full
learning_rate: 1e-4  # 너무 큰 학습률
warmup_steps: 10     # 너무 짧은 warmup
```

**해결**:
```yaml
model_name_or_path: meta-llama/Meta-Llama-3-70B-Instruct
finetuning_type: lora  # 더 안전한 방법
learning_rate: 1e-5   # 더 작은 학습률
warmup_steps: 500     # 충분한 warmup
```

## 🔧 디버깅 및 모니터링

### Loss 그래프 분석

#### 정상적인 Warmup 패턴
```python
# Loss 변화 패턴
Step 1-100 (warmup):
  - Loss가 빠르게 감소 (작은 학습률이지만 효과적)
  - 안정적인 감소 곡선
  
Step 101+ (main training):
  - 계속해서 안정적 감소
  - 가끔 작은 fluctuation은 정상
```

#### 문제가 있는 패턴들

**Warmup이 부족한 경우**:
```python
Step 1-10: Loss가 급격히 변동하거나 증가
Step 11+: 불안정한 학습 패턴
```

**Warmup이 과도한 경우**:
```python
Step 1-500: 매우 느린 Loss 감소
Step 501+: 짧은 구간에서 급격한 변화 시도
```

### 로깅을 통한 모니터링

```yaml
# 상세 모니터링 설정
logging_steps: 10  # 자주 로깅
save_steps: 100
eval_steps: 100

# 시각화 도구 사용
report_to: tensorboard
use_swanlab: true
swanlab_project: warmup_analysis
```

### 학습률 스케줄 확인 코드

```python
# 학습률 변화 시각화 (디버깅용)
import matplotlib.pyplot as plt
import numpy as np

def plot_lr_schedule(total_steps, warmup_steps, target_lr, scheduler_type="cosine"):
    steps = np.arange(1, total_steps + 1)
    lrs = []
    
    for step in steps:
        if step <= warmup_steps:
            # Warmup phase
            lr = target_lr * (step / warmup_steps)
        else:
            # Main training phase
            if scheduler_type == "cosine":
                progress = (step - warmup_steps) / (total_steps - warmup_steps)
                lr = target_lr * 0.5 * (1 + np.cos(np.pi * progress))
            elif scheduler_type == "linear":
                lr = target_lr * (total_steps - step) / (total_steps - warmup_steps)
            else:  # constant
                lr = target_lr
        
        lrs.append(lr)
    
    plt.figure(figsize=(10, 6))
    plt.plot(steps, lrs)
    plt.axvline(x=warmup_steps, color='red', linestyle='--', label='Warmup End')
    plt.xlabel('Training Steps')
    plt.ylabel('Learning Rate')
    plt.title(f'Learning Rate Schedule (warmup_steps={warmup_steps})')
    plt.legend()
    plt.grid(True)
    plt.show()

# 사용 예시
plot_lr_schedule(1000, 100, 5e-5, "cosine")
```

## 💡 고급 활용 팁

### 1. 동적 Warmup 조정

대용량 모델이나 불안정한 데이터셋의 경우:

```yaml
# 1단계: 긴 warmup으로 시작
warmup_steps: 1000
learning_rate: 1e-5
num_train_epochs: 1

# 2단계: 안정화 확인 후 짧은 warmup으로 계속
warmup_steps: 100  
learning_rate: 5e-5
num_train_epochs: 2
```

### 2. 다중 단계 Warmup

```yaml
# 매우 큰 모델의 경우 점진적 접근
# Phase 1: 매우 보수적
warmup_steps: 500
learning_rate: 1e-6

# Phase 2: 중간 정도
warmup_steps: 200
learning_rate: 5e-6

# Phase 3: 목표 학습률
warmup_steps: 100
learning_rate: 1e-5
```

### 3. 도메인별 최적화

#### 코드 생성 모델
```yaml
# 코드의 정확성이 중요 → 신중한 warmup
warmup_steps: 300
learning_rate: 3e-5
lr_scheduler_type: cosine
```

#### 창작 모델
```yaml
# 창의성 중시 → 상대적으로 짧은 warmup
warmup_steps: 100
learning_rate: 5e-5
lr_scheduler_type: constant
```

## 📋 최종 권장사항

### 일반적인 가이드라인

1. **기본값**: 전체 훈련 스텝의 10%
2. **최소값**: 50 steps
3. **최대값**: 전체 스텝의 20%

### 상황별 추천

#### 초심자용 안전 설정
```yaml
warmup_steps: 200
learning_rate: 3e-5
lr_scheduler_type: cosine
```

#### 실험적 설정
```yaml
warmup_steps: 50
learning_rate: 1e-4
lr_scheduler_type: linear
```

#### 프로덕션 안정성 중시
```yaml
warmup_steps: 500
learning_rate: 1e-5
lr_scheduler_type: cosine
```

Warmup steps는 모델 훈련의 안정성과 성능에 큰 영향을 미치는 중요한 하이퍼파라미터입니다. 적절한 설정을 통해 더 안정적이고 효과적인 파인튜닝을 달성할 수 있습니다.

