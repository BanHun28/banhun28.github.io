---
title: Motivation and Basics
date: 2025-08-11 12:00:28 +0900
categories: [machine learning, math]
tags: [machine learning, math, mle, map, kooc]     # TAG names should always be lowercase
---

## 들어가며: 머신러닝이란 무엇인가?

머신러닝은 우리 일상 곳곳에 존재합니다. 이메일 스팸 필터링, 주식 예측, 번호판 인식, SNS 추천 시스템까지 - 모든 것이 머신러닝의 영역입니다. 

**Tom Mitchell의 머신러닝 정의:**
> 컴퓨터 프로그램이 경험 E를 통해 작업 T에서의 성능 P가 향상될 때, 그 프로그램은 학습한다고 할 수 있습니다.

즉, 머신러닝은 **데이터(경험)로부터 가장 가능성 높고 근사한 답을 제공하는 일반화된 함수를 선택하는 것**입니다.

## 머신러닝의 종류

### 1. 지도학습 (Supervised Learning)
- **정답을 알고 있는 경우**
- 분류(Classification): 스팸/정상 메일 구분
- 회귀(Regression): 주택 가격 예측

### 2. 비지도학습 (Unsupervised Learning)  
- **정답을 모르는 경우**
- 군집화(Clustering): 고객 그룹 분석
- 차원 축소: 데이터 압축

### 3. 강화학습 (Reinforcement Learning)
- **목표는 알지만 방법을 모르는 경우**
- 게임 AI, 로봇 제어

## 실전 예제: 갑부의 도박 딜레마

억만장자가 압정 던지기 게임에서 승리하기 위해 당신에게 자문을 구했다고 상상해보세요.

### 🎯 문제 상황
- 압정을 5번 던진 결과: 앞면 3번, 뒷면 2번
- 질문: "다음 게임에서 앞면이 나올 확률은?"

## 이항분포(Binomial Distribution)의 수학적 기초

압정 던지기는 **베르누이 시행**의 연속입니다. 앞면이 나올 확률을 θ라고 하면:

**이항분포의 확률질량함수:**
```
P(k번 성공 | n번 시행) = C(n,k) × θ^k × (1-θ)^(n-k)
```

여기서 $C(n,k) = \frac{n!}{k!(n-k)!}$는 조합입니다.

**우리 예제에 적용:**
- n = 5 (총 시행 횟수)
- k = $a_H$ = 3 (앞면 횟수)  
- $a_T$ = 2 (뒷면 횟수)

따라서 관찰된 데이터의 확률은:
```
P(D|θ) = $\theta^3 \times (1-\theta)^2$
```

**이항분포의 평균과 분산 유도:**

평균: $E[X] = n\theta$
$$
E[X] = \sum_{k=0}^{n} k \times C(n,k) \times \theta^k \times (1-\theta)^{n-k}
$$

$k \times C(n,k) = n \times C(n-1,k-1)$ 이므로

$$
E[X] = n\theta \times \sum_{k=1}^{n} C(n-1,k-1) \times \theta^{k-1} \times (1-\theta)^{n-k}
     = n\theta \times (\theta + (1-\theta))^{n-1} = n\theta
$$

분산: $Var(X) = n\theta(1-\theta)$

### 📊 MLE (Maximum Likelihood Estimation) 접근법

**핵심 아이디어**: 관찰된 데이터가 나올 가능성을 최대화하는 파라미터를 찾는다.

**쉬운 설명**: 압정을 5번 던져서 "앞앞뒤앞뒤"가 나왔습니다. 이제 이 결과를 보고 "이런 결과가 나오려면 압정의 앞면 확률이 얼마였을까?"라고 역추론하는 것입니다. 

- 만약 앞면 확률이 0.1이라면? → 앞면 3번이 나올 가능성은 매우 낮음
- 만약 앞면 확률이 0.9라면? → 뒷면 2번이 나올 가능성은 매우 낮음  
- 만약 앞면 확률이 0.6이라면? → 앞면 3번, 뒷면 2번이 나올 가능성이 가장 높음!

즉, **실제로 관찰된 결과가 가장 그럴듯하게 나올 수 있는 확률값을 찾는 것**이 MLE의 핵심입니다.

**1단계: 가능도 함수 설정**
```
L(θ) = P(D|θ) = $\theta^{a_H} \times (1-\theta)^{a_T}$
```

**2단계: 로그 가능도 함수**
직접 미분하기 어려우므로 로그를 취합니다:

**로그를 취해도 되는 이유:**
로그함수는 **단조증가함수**이므로, 원래 함수의 최대값과 로그를 취한 함수의 최대값이 같은 지점에서 발생합니다.
- 만약 θ₁에서 L(θ₁) > L(θ₂)라면
- log L(θ₁) > log L(θ₂)도 성립합니다
- 따라서 argmax L(θ) = argmax log L(θ)

**로그를 취하는 실용적 이유:**
1. **곱셈이 덧셈으로 변환**: θ³ × (1-θ)² → 3log θ + 2log(1-θ)
2. **미분이 간단해짐**: 지수함수 미분 → 간단한 분수형태
3. **수치적 안정성**: 매우 작은 확률값들의 곱셈으로 인한 언더플로우 방지

```
log L(θ) = $a_H \times \log \theta + a_T \times \log(1-\theta)$
```

**3단계: 미분하여 최적값 찾기**
```
$\frac{d(\log L)}{d\theta} = \frac{a_H}{\theta} - \frac{a_T}{1-\theta} = 0$

이를 풀면:
$a_H(1-\theta) = a_T \times \theta$
$a_H - a_H \times \theta = a_T \times \theta$  
$a_H = \theta(a_H + a_T)$

∴ $\theta = \frac{a_H}{a_H + a_T}$
```

**4단계: 최대값임을 확인**
2차 미분을 통해 확인:
```
$\frac{d^2(\log L)}{d\theta^2} = -\frac{a_H}{\theta^2} - \frac{a_T}{(1-\theta)^2} < 0$
```

음수이므로 최대값입니다.

**MLE 결과:**
```
$\hat{\theta}_{MLE} = \frac{a_H}{a_H + a_T} = \frac{3}{5} = 0.6$
```

### 📈 MAP (Maximum A Posteriori) 접근법

**베이즈의 개입**: "잠깐, 사전 지식을 고려해야 하지 않나요?"

**베이즈 정리:**
```
P(θ|D) = P(D|θ) × P(θ) / P(D)

Posterior = (Likelihood × Prior) / Normalizing Constant
```

**각 용어의 의미:**

- **P(θ|D) - 사후분포(Posterior)**: 데이터를 관찰한 **후에** 업데이트된 θ에 대한 믿음
  - "압정을 5번 던진 결과를 본 후, 앞면 확률이 θ일 가능성"
  
- **P(D|θ) - 가능도(Likelihood)**: 주어진 θ값에서 데이터 D가 관찰될 확률
  - "앞면 확률이 θ라면, 실제로 관찰된 '앞앞뒤앞뒤' 결과가 나올 확률"
  
- **P(θ) - 사전분포(Prior)**: 데이터를 보기 **전에** 가지고 있던 θ에 대한 믿음
  - "압정을 던지기 전에 생각했던 앞면 확률의 분포" (예: 보통 동전처럼 0.5 근처일 것)
  
- **P(D) - 증거(Evidence/Normalizing Constant)**: 모든 가능한 θ값을 고려했을 때 데이터 D가 나올 전체 확률
  - 분모 역할로 확률의 합이 1이 되도록 정규화하는 상수

**베이즈 정리 유도 과정:**
조건부 확률의 정의에서:
```
P(A|B) = P(A∩B)/P(B)
P(B|A) = P(A∩B)/P(A)

따라서: P(A∩B) = P(A|B)×P(B) = P(B|A)×P(A)

정리하면: P(B|A) = P(A|B)×P(B)/P(A)
```

## 베타분포(Beta Distribution): 완벽한 사전분포

**베타분포를 선택하는 이유:**
1. [0,1] 구간에서 정의 (확률 모델링에 적합)
2. 이항분포와 **켤레사전분포** 관계

**베타분포의 확률밀도함수:**
```
f(θ; α, β) = θ^(α-1) × (1-θ)^(β-1) / B(α,β)
```

여기서 베타함수: `$B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$`
감마함수: `$\Gamma(\alpha) = (\alpha-1)!$` (α가 자연수일 때)

**베타분포의 평균 유도:**
```
E[θ] = ∫₀¹ θ × f(θ; α, β) dθ
     = ∫₀¹ θ^α × (1-θ)^(β-1) / B(α,β) dθ
     = B(α+1,β) / B(α,β)
     = α/(α+β)
```

**켤레사전분포의 성질:**
베타분포 Beta(α,β)를 사전분포로 사용하면:
```
P(θ|D) ∝ P(D|θ) × P(θ)
       ∝ $\theta^{a_H} \times (1-\theta)^{a_T} \times \theta^{(\alpha-1)} \times (1-\theta)^{(\beta-1)}$
       ∝ $\theta^{(a_H+\alpha-1)} \times (1-\theta)^{(a_T+\beta-1)}$
```

이는 **Beta($a_H+\alpha$, $a_T+\beta$) 분포**입니다!

**MAP 추정량 유도:**
사후분포의 최빈값(mode)을 구합니다:
```
$f(\theta) \propto \theta^{(a_H+\alpha-1)} \times (1-\theta)^{(a_T+\beta-1)}$

$\log f(\theta) = (a_H+\alpha-1)\log \theta + (a_T+\beta-1)\log(1-\theta) + $ 상수

$\frac{d(\log f)}{d\theta} = \frac{a_H+\alpha-1}{\theta} - \frac{a_T+\beta-1}{1-\theta} = 0$

풀면: $\theta = \frac{a_H+\alpha-1}{a_H+a_T+\alpha+\beta-2}$
```

**MAP 결과:**
```
$\hat{\theta}_{MAP} = \frac{a_H+\alpha-1}{a_H+a_T+\alpha+\beta-2}$
```

### 🤔 MLE vs MAP: 어떤 차이가 있을까?

**수학적 관계:**
```
$\hat{\theta}_{MAP} = \frac{a_H+\alpha-1}{n+\alpha+\beta-2}$
       $= \frac{a_H/n + (\alpha-1)/n}{1 + (\alpha+\beta-2)/n}$
```

**극한에서의 수렴:**
$n \to \infty$일 때: $\hat{\theta}_{MAP} \to a_H/n = \hat{\theta}_{MLE}$

**데이터가 적을 때**: MAP가 더 안정적 (사전 지식 활용)
**데이터가 많을 때**: MLE ≈ MAP (데이터가 사전 지식을 압도)

## PAC Learning: 확률적 근사 학습

**Probably Approximately Correct Learning**

**Hoeffding 부등식:**
독립적인 베르누이 시행에서:
```
P(|θ̂ - θ*| ≥ ε) ≤ 2e^(-2Nε²)
```

**공식의 각 요소 설명:**

- **θ̂ (세타 햇)**: 우리가 추정한 확률값 (표본평균)
  - 예: 압정을 N번 던져서 계산한 앞면 확률 = (앞면 횟수)/N
  
- **θ\* (세타 스타)**: 실제 진짜 확률값 (모집단 평균)  
  - 예: 압정의 진짜 앞면 확률 (우리가 알고 싶어하는 참값)
  
- **|θ̂ - θ\*|**: 추정값과 실제값 사이의 **절댓값 오차**
  - 예: 실제는 0.6인데 0.55로 추정했다면 오차는 0.05
  
- **ε (엡실론)**: 허용 가능한 **오차 한계**
  - 예: "0.1 이내로 정확하게 추정하고 싶다" → ε = 0.1
  
- **N**: **시행 횟수** (표본 크기)
  - 예: 압정을 몇 번 던졌는가
  
- **2e^(-2Nε²)**: 오차가 ε보다 클 확률의 **상한(upper bound)**

**공식이 말하는 것:**
"N번 시행해서 구한 추정값이 실제값과 ε 이상 차이날 확률은 2e^(-2Nε²)보다 작거나 같다"

**직관적 해석:**
- N이 클수록 (더 많이 시행할수록) → 우변이 작아짐 → 정확한 추정 가능
- ε이 작을수록 (더 정확한 추정을 원할수록) → 우변이 작아짐 → 더 많은 시행 필요

**필요한 시행 횟수 계산:**
오차 ε = 0.1, 신뢰도 99.99% (δ = 0.0001)를 원한다면:
```
2e^(-2N×0.01) ≤ 0.0001
e^(-0.02N) ≤ 0.00005
N ≥ -log(0.00005)/0.02 ≈ 499,424
```

약 50만 번의 시행이 필요합니다!

- **Probably**: 99.99% 확률로
- **Approximately**: 오차 ±0.1 이내에서

## 확률과 분포의 기초

### 확률의 기본 성질과 유도

**확률의 공리:**
1. P(E) ≥ 0 (비음성)
2. P(Ω) = 1 (정규성)  
3. P(∪Ei) = ΣP(Ei) (가산 가법성, 상호배타적 사건)

**기본 성질 유도:**

**성질 1**: P(∅) = 0
```
증명: Ω = Ω ∪ ∅이고 Ω ∩ ∅ = ∅이므로
P(Ω) = P(Ω) + P(∅) = 1
따라서 P(∅) = 0
```

**성질 2**: P(E^c) = 1 - P(E)
```
증명: Ω = E ∪ E^c이고 E ∩ E^c = ∅이므로
1 = P(E) + P(E^c)
따라서 P(E^c) = 1 - P(E)
```

### 조건부 확률
```
P(A|B) = P(A∩B)/P(B), P(B) > 0
```

**전확률 공식:**
```
P(A) = Σ P(A|Bi) × P(Bi)
```

### 주요 확률 분포

#### 1. 정규분포 (Normal Distribution)
```
f(x; μ, σ) = (1/σ√2π) × exp(-(x-μ)²/2σ²)
표기: N(μ, σ²)
평균: μ, 분산: σ²
```
- 가장 일반적인 연속 분포
- 중심극한정리에 의해 자연 현상에서 자주 관찰

#### 2. 베타분포 (Beta Distribution)
```
f(θ; α, β) = θ^(α-1) × (1-θ)^(β-1) / B(α,β)
표기: Beta(α, β)
평균: α/(α+β), 분산: αβ/((α+β)²(α+β+1))
```
- [0,1] 구간에서 정의
- 확률의 확률을 모델링할 때 유용

#### 3. 이항분포 (Binomial Distribution)
```
f(k; n, p) = C(n,k) × p^k × (1-p)^(n-k)
표기: B(n, p)
평균: np, 분산: np(1-p)
```
- 성공/실패가 명확한 독립 시행
- 압정 던지기 같은 베르누이 시행

#### 4. 다항분포 (Multinomial Distribution)
```
f(x₁,...,xₖ; n, p₁,...,pₖ) = n!/(x₁!...xₖ!) × p₁^x₁ × ... × pₖ^xₖ
평균: E[Xi] = npi, 분산: Var(Xi) = npi(1-pi)
```
- 이항분포의 일반화
- 여러 선택지가 있는 경우 (A, B, C, D 중 선택)

## 마치며

머신러닝은 복잡해 보이지만, 결국 **데이터로부터 패턴을 찾아 미래를 예측하는 것**입니다. 압정 던지기 예제에서 보았듯이, 수학적 원리를 이해하면 복잡한 실세계 문제도 체계적으로 접근할 수 있습니다.

특히 MLE와 MAP의 수학적 유도 과정을 완전히 이해하면, 더 복잡한 머신러닝 알고리즘의 원리도 쉽게 파악할 수 있을 것입니다. 기초를 탄탄히 하고, 꾸준히 실습하며, 수학적 직관을 기르는 것이 성공적인 머신러닝 엔지니어가 되는 길입니다.

---

**참고 문헌**
- Bishop, C. M. (2006). Pattern Recognition and Machine Learning, Chapter 1-2
- KAIST 문일철 교수님 강의자료

